#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡å¼ºåŠ¿è‚¡ç¥¨æ‰«æå™¨
ä½¿ç”¨akshareè·å–Aè‚¡æ•°æ®ï¼Œåº”ç”¨ä¸ç¾è‚¡ç›¸åŒçš„æŠ€æœ¯æŒ‡æ ‡ç­›é€‰é€»è¾‘
"""

import os
import logging
import pandas as pd
import datetime
import time
import random
import argparse
import json
from pathlib import Path
from sqlalchemy import Column, String, Float, Date, Integer, UniqueConstraint, DateTime
from sqlalchemy.orm import declarative_base

from storage import get_db, Base # å¯¼å…¥ Base

logger = logging.getLogger(__name__)
# ============ æ¸…é™¤ä»£ç†è®¾ç½®ï¼ˆAè‚¡æ•°æ®æºä¸éœ€è¦ä»£ç†ï¼‰============
# akshare è®¿é—®ä¸œæ–¹è´¢å¯Œç­‰å›½å†…æ•°æ®æºæ—¶ï¼Œä»£ç†åè€Œä¼šå¯¼è‡´ SSL é”™è¯¯
for proxy_key in ['http_proxy', 'https_proxy', 'HTTP_PROXY', 'HTTPS_PROXY', 'ALL_PROXY', 'all_proxy']:
    if proxy_key in os.environ:
        del os.environ[proxy_key]
logger.info("ğŸ‡¨ğŸ‡³ Aè‚¡æ‰«æå™¨ - å·²æ¸…é™¤ä»£ç†è®¾ç½®ï¼ˆå›½å†…æ•°æ®æºæ— éœ€ä»£ç†ï¼‰")
# ================================================================
# å»¶æ—¶å‚æ•°
REQUEST_DELAY_MIN = 0.1
REQUEST_DELAY_MAX = 0.3
BATCH_SIZE = 100
BATCH_PAUSE = 2

# APIè¯·æ±‚é™åˆ¶å‚æ•°
MAX_RETRIES = 3
RETRY_BACKOFF = 2

# è·¯å¾„é…ç½® (ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•)
ROOT_DIR = Path(__file__).parent # ä¿®æ”¹ ROOT_DIR ä¸ºå½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
TICKER_STORAGE_DIR = ROOT_DIR / "ticker_storage"
TICKER_STORAGE_DIR.mkdir(exist_ok=True)
CACHE_DIR = ROOT_DIR / "cache_cn"
CACHE_DIR.mkdir(exist_ok=True)
OUTPUT_DIR = ROOT_DIR / "output"
OUTPUT_DIR.mkdir(exist_ok=True)
LOG_DIR = ROOT_DIR / "logs" # æ–°å¢ LOG_DIR
LOG_DIR.mkdir(exist_ok=True) # ç¡®ä¿ logs ç›®å½•å­˜åœ¨
LOG_FILE_PATH = LOG_DIR / "strong_stocks_cn.log" # ä¿®æ”¹æ—¥å¿—æ–‡ä»¶è·¯å¾„

# å·²é€€å¸‚è‚¡ç¥¨è¿‡æ»¤æ–‡ä»¶
DELISTED_STOCKS_FILE = TICKER_STORAGE_DIR / "delisted_stocks_cn.txt"

# SQLAlchemy ORM åŸºç±» (å·²ä» storage å¯¼å…¥ï¼Œè¿™é‡Œä¸å†é‡å¤å®šä¹‰)
# Base = declarative_base()

class StrongStock(Base):
    """å¼ºåŠ¿è‚¡ç¥¨æ•°æ®æ¨¡å‹"""
    __tablename__ = 'strong_stocks'
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    stock_code = Column(String(20), nullable=False, index=True, comment='è‚¡ç¥¨ä»£ç ')
    stock_name = Column(String(100), nullable=False, comment='è‚¡ç¥¨åç§°')
    close_price = Column(Float, comment='æ”¶ç›˜ä»·')
    market_cap = Column(String(50), comment='å¸‚å€¼(æ˜¾ç¤ºæ–‡æœ¬)')
    industry = Column(String(100), comment='è¡Œä¸š')
    list_date = Column(String(20), comment='ä¸Šå¸‚æ—¥æœŸ')
    ma5 = Column(Float, comment='MA5')
    ma10 = Column(Float, comment='MA10')
    ma20 = Column(Float, comment='MA20')
    macd = Column(Float, comment='MACD')
    macd_dea = Column(Float, comment='MACD_DEA')
    vol_ratio = Column(Float, comment='æˆäº¤é‡å€æ•°')
    increase_20d = Column(Float, comment='20å¤©æ¶¨å¹…(%)')
    week_52_range = Column(String(50), comment='52å‘¨æ³¢åŠ¨å¹…åº¦')
    week_52_high = Column(Float, comment='52å‘¨æœ€é«˜')
    pct_from_high = Column(String(50), comment='è·52å‘¨é«˜ç‚¹')
    week_52_low = Column(Float, comment='52å‘¨æœ€ä½')
    pct_from_low = Column(String(50), comment='è·52å‘¨ä½ç‚¹')
    met_conditions = Column(String(50), comment='æ»¡è¶³æ¡ä»¶')
    condition_details = Column(String(500), comment='æ¡ä»¶è¯¦æƒ…')
    scan_time = Column(DateTime, default=datetime.datetime.now, comment='æ‰«ææ—¶é—´')
    
    __table_args__ = (
        UniqueConstraint('scan_time', 'stock_code', name='uix_strong_stock_scan_time_code'),
    )

def get_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Aè‚¡è‚¡ç¥¨æ‰«æå·¥å…·')
    parser.add_argument('--use-cache', action='store_true', help='ä½¿ç”¨ç¼“å­˜çš„tickeråˆ—è¡¨ï¼ˆé»˜è®¤æ¯æ¬¡éƒ½è·å–å…¨éƒ¨Aè‚¡ï¼‰')
    parser.add_argument('--test', '-t', type=int, default=0, help='æµ‹è¯•æ¨¡å¼ï¼šåªæ‰«æå‰Nåªè‚¡ç¥¨')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…é™¤æ‰€æœ‰ç¼“å­˜çš„è‚¡ç¥¨æ•°æ®')
    parser.add_argument('--use-data-cache', action='store_true', help='ä½¿ç”¨è‚¡ç¥¨æ•°æ®ç¼“å­˜')
    parser.add_argument('--market', '-m', type=str, default='all',
                        choices=['all', 'sh', 'sz', 'bj', 'cyb', 'kcb'],
                        help='é€‰æ‹©å¸‚åœºï¼šall=å…¨éƒ¨, sh=ä¸Šæµ·ä¸»æ¿, sz=æ·±åœ³ä¸»æ¿, bj=åŒ—äº¤æ‰€, cyb=åˆ›ä¸šæ¿, kcb=ç§‘åˆ›æ¿')
    # åœ¨åŒ…å†…è¿è¡Œæ—¶ï¼Œç›´æ¥è§£æå¯èƒ½ä¼šä¸ uvicorn çš„å‚æ•°å†²çªï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨é»˜è®¤å€¼
    # args = parser.parse_args()
    # return args.use_cache, args.test, args.clear_cache, args.use_data_cache, args.market
    return False, 0, False, True, 'all'


USE_TICKER_CACHE, TEST_LIMIT, CLEAR_CACHE, USE_DATA_CACHE, MARKET_FILTER = get_args()


def log_strong_stock(stock_info):
    """è®°å½•å¼ºåŠ¿è‚¡ç¥¨åˆ°æ—¥å¿—æ–‡ä»¶"""
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_message = f"[{timestamp}] ğŸ¯ æ£€æµ‹åˆ°æ»¡è¶³æ¡ä»¶çš„Aè‚¡: {stock_info['ä»£ç ']} - {stock_info['åç§°']}\n"
    log_message += f"   ğŸ’° æ”¶ç›˜ä»·: Â¥{stock_info['æ”¶ç›˜ä»·']}\n"
    log_message += f"   ğŸ¢ å¸‚å€¼: {stock_info.get('å¸‚å€¼', 'N/A')}\n"
    log_message += f"   ğŸ“… ä¸Šå¸‚æ—¥æœŸ: {stock_info.get('ä¸Šå¸‚æ—¥æœŸ', 'N/A')}\n"

    # æ·»åŠ 52å‘¨ä»·æ ¼ä¿¡æ¯
    week_52_range = stock_info.get('52å‘¨æ³¢åŠ¨å¹…åº¦', 'N/A')
    week_52_high = stock_info.get('52å‘¨æœ€é«˜', 'N/A')
    week_52_low = stock_info.get('52å‘¨æœ€ä½', 'N/A')
    pct_from_high = stock_info.get('è·52å‘¨é«˜ç‚¹', 'N/A')
    pct_from_low = stock_info.get('è·52å‘¨ä½ç‚¹', 'N/A')
    if week_52_range != 'N/A':
        log_message += f"   ğŸ“Š 52å‘¨æ³¢åŠ¨å¹…åº¦: {week_52_range}\n"
    if week_52_high != 'N/A':
        log_message += f"   ğŸ“Š 52å‘¨æœ€é«˜: Â¥{week_52_high} (å½“å‰è·é«˜ç‚¹: {pct_from_high})\n"
    if week_52_low != 'N/A':
        log_message += f"   ğŸ“Š 52å‘¨æœ€ä½: Â¥{week_52_low} (å½“å‰è·ä½ç‚¹: {pct_from_low})\n"

    log_message += f"   ğŸ“ˆ 20å¤©æ¶¨å¹…: {stock_info['20å¤©æ¶¨å¹…']}%\n"
    log_message += f"   â­ æ»¡è¶³æ¡ä»¶: {stock_info['æ»¡è¶³æ¡ä»¶']}\n"
    log_message += f"   ğŸ“Š æ¡ä»¶è¯¦æƒ…: {stock_info['æ¡ä»¶è¯¦æƒ…']}\n"

    # æ·»åŠ è¡Œä¸šä¿¡æ¯
    industry = stock_info.get('è¡Œä¸š', 'N/A')
    if industry and industry != 'N/A':
        log_message += f"   ğŸ­ è¡Œä¸š: {industry}\n"

    log_message += f"   {'=' * 50}\n\n"

    # å†™å…¥æ—¥å¿—æ–‡ä»¶
    try:
        with open(LOG_FILE_PATH, 'a', encoding='utf-8') as f:
            f.write(log_message)
    except Exception as e:
        logger.error(f"å†™å…¥æ—¥å¿—å¤±è´¥: {e}")

    # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
    logger.info(log_message.strip())


def fetch_all_cn_stocks():
    """è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨ï¼ˆé€šè¿‡è…¾è®¯è´¢ç»æ‰¹é‡è·å–ï¼‰"""
    import requests

    def get_stocks_batch_tencent(codes, market_prefix):
        """é€šè¿‡è…¾è®¯è´¢ç»æ‰¹é‡è·å–è‚¡ç¥¨ä¿¡æ¯"""
        valid_stocks = []
        batch_size = 100  # æ¯æ¬¡100ä¸ª

        for i in range(0, len(codes), batch_size):
            batch = codes[i:i + batch_size]
            query_codes = ','.join([f"{market_prefix}{code}" for code in batch])
            url = f"http://qt.gtimg.cn/q={query_codes}"

            try:
                resp = requests.get(url, timeout=20)
                if resp.status_code == 200:
                    # ä½¿ç”¨GBKè§£ç 
                    try:
                        text = resp.content.decode('gbk')
                    except:
                        text = resp.text

                    for line in text.strip().split(';'):
                        if '="' in line and '~' in line:
                            try:
                                parts = line.split('~')
                                if len(parts) >= 4:
                                    name = parts[1].strip()
                                    code = parts[2].strip()
                                    price_str = parts[3].strip()
                                    # æœ‰åç§°ã€ä»£ç æ­£ç¡®ã€ä»·æ ¼>0
                                    if name and code and len(code) == 6:
                                        try:
                                            price = float(price_str)
                                            if price > 0:
                                                valid_stocks.append((code, name))
                                        except:
                                            pass
                            except:
                                continue
                time.sleep(0.02)
            except:
                continue

            if (i // batch_size) % 20 == 0 and i > 0:
                logger.info(f"   è¿›åº¦: {i}/{len(codes)}, æœ‰æ•ˆ: {len(valid_stocks)} åª")

        return valid_stocks

    logger.info("ğŸ“¡ æ­£åœ¨é€šè¿‡è…¾è®¯è´¢ç»è·å–å…¨éƒ¨Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
    all_stocks = []

    # ä¸Šæµ·Aè‚¡ä»£ç èŒƒå›´ï¼ˆç²¾ç®€ï¼‰
    logger.info("   ğŸ” è·å–ä¸Šæµ·Aè‚¡...")
    sh_codes = []
    for i in range(600000, 606000):  # ä¸»æ¿ 600000-605999
        sh_codes.append(str(i).zfill(6))
    for i in range(688000, 689500):  # ç§‘åˆ›æ¿ 688000-689499
        sh_codes.append(str(i).zfill(6))

    sh_valid = get_stocks_batch_tencent(sh_codes, 'sh')
    logger.info(f"   âœ… ä¸Šæµ·Aè‚¡: {len(sh_valid)} åª")
    all_stocks.extend(sh_valid)

    # æ·±åœ³Aè‚¡ä»£ç èŒƒå›´ï¼ˆç²¾ç®€ï¼‰
    logger.info("   ğŸ” è·å–æ·±åœ³Aè‚¡...")
    sz_codes = []
    for i in range(1, 3500):  # ä¸»æ¿ 000001-003499
        sz_codes.append(str(i).zfill(6))
    for i in range(300000, 302000):  # åˆ›ä¸šæ¿ 300000-301999
        sz_codes.append(str(i).zfill(6))

    sz_valid = get_stocks_batch_tencent(sz_codes, 'sz')
    logger.info(f"   âœ… æ·±åœ³Aè‚¡: {len(sz_valid)} åª")
    all_stocks.extend(sz_valid)

    if all_stocks:
        unique_stocks = list(dict.fromkeys(all_stocks))
        logger.info(f"âœ… æˆåŠŸè·å– {len(unique_stocks)} åªAè‚¡")
        return unique_stocks

    # å¤‡ç”¨ï¼šä½¿ç”¨å†…ç½®åˆ—è¡¨
    logger.warning("âš ï¸  è…¾è®¯è´¢ç»è·å–å¤±è´¥ï¼Œä½¿ç”¨å†…ç½®è‚¡ç¥¨åˆ—è¡¨...")
    base_stocks = get_builtin_cn_stocks()
    logger.info(f"âœ… ä½¿ç”¨å†…ç½®åˆ—è¡¨ï¼Œå…± {len(base_stocks)} åªAè‚¡")
    return base_stocks


def get_builtin_cn_stocks():
    """å†…ç½®çš„åŸºç¡€Aè‚¡åˆ—è¡¨ï¼ˆä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    # åŒ…å«ä¸»è¦çš„å¤§ä¸­å°ç›˜è‚¡ç¥¨ä»£ç 
    stocks = [
        # ä¸Šè¯50ä¸»è¦æˆåˆ†è‚¡
        ("600000", "æµ¦å‘é“¶è¡Œ"), ("600016", "æ°‘ç”Ÿé“¶è¡Œ"), ("600028", "ä¸­å›½çŸ³åŒ–"),
        ("600030", "ä¸­ä¿¡è¯åˆ¸"), ("600036", "æ‹›å•†é“¶è¡Œ"), ("600048", "ä¿åˆ©å‘å±•"),
        ("600050", "ä¸­å›½è”é€š"), ("600104", "ä¸Šæ±½é›†å›¢"), ("600111", "åŒ—æ–¹ç¨€åœŸ"),
        ("600276", "æ’ç‘åŒ»è¯"), ("600309", "ä¸‡ååŒ–å­¦"), ("600519", "è´µå·èŒ…å°"),
        ("600585", "æµ·èºæ°´æ³¥"), ("600690", "æµ·å°”æ™ºå®¶"), ("600809", "å±±è¥¿æ±¾é…’"),
        ("600887", "ä¼Šåˆ©è‚¡ä»½"), ("600900", "é•¿æ±Ÿç”µåŠ›"), ("601012", "éš†åŸºç»¿èƒ½"),
        ("601088", "ä¸­å›½ç¥å"), ("601166", "å…´ä¸šé“¶è¡Œ"), ("601318", "ä¸­å›½å¹³å®‰"),
        ("601398", "å·¥å•†é“¶è¡Œ"), ("601628", "ä¸­å›½äººå¯¿"), ("601668", "ä¸­å›½å»ºç­‘"),
        ("601888", "ä¸­å›½ä¸­å…"), ("601899", "ç´«é‡‘çŸ¿ä¸š"), ("603259", "è¯æ˜åº·å¾·"),
        ("603288", "æµ·å¤©å‘³ä¸š"), ("603501", "éŸ¦å°”è‚¡ä»½"),

        # æ·±è¯æˆåˆ†è‚¡
        ("000001", "å¹³å®‰é“¶è¡Œ"), ("000002", "ä¸‡ç§‘A"), ("000063", "ä¸­å…´é€šè®¯"),
        ("000100", "TCLç§‘æŠ€"), ("000157", "ä¸­è”é‡ç§‘"), ("000333", "ç¾çš„é›†å›¢"),
        ("000338", "æ½æŸ´åŠ¨åŠ›"), ("000425", "å¾å·¥æœºæ¢°"), ("000538", "äº‘å—ç™½è¯"),
        ("000568", "æ³¸å·è€çª–"), ("000625", "é•¿å®‰æ±½è½¦"), ("000651", "æ ¼åŠ›ç”µå™¨"),
        ("000661", "é•¿æ˜¥é«˜æ–°"), ("000725", "äº¬ä¸œæ–¹A"), ("000776", "å¹¿å‘è¯åˆ¸"),
        ("000858", "äº”ç²®æ¶²"), ("000895", "åŒæ±‡å‘å±•"), ("000938", "ç´«å…‰è‚¡ä»½"),
        ("002001", "æ–°å’Œæˆ"), ("002007", "åå…°ç”Ÿç‰©"), ("002027", "åˆ†ä¼—ä¼ åª’"),
        ("002049", "ç´«å…‰å›½å¾®"), ("002050", "ä¸‰èŠ±æ™ºæ§"), ("002120", "éŸµè¾¾è‚¡ä»½"),
        ("002142", "å®æ³¢é“¶è¡Œ"), ("002230", "ç§‘å¤§è®¯é£"), ("002236", "å¤§åè‚¡ä»½"),
        ("002241", "æ­Œå°”è‚¡ä»½"), ("002271", "ä¸œæ–¹é›¨è™¹"), ("002304", "æ´‹æ²³è‚¡ä»½"),
        ("002352", "é¡ºä¸°æ§è‚¡"), ("002410", "å¹¿è”è¾¾"), ("002415", "æµ·åº·å¨è§†"),
        ("002460", "èµ£é”‹é”‚ä¸š"), ("002475", "ç«‹è®¯ç²¾å¯†"), ("002594", "æ¯”äºšè¿ª"),
        ("002714", "ç‰§åŸè‚¡ä»½"), ("002812", "æ©æ·è‚¡ä»½"), ("002916", "æ·±å—ç”µè·¯"),

        # åˆ›ä¸šæ¿è‚¡ç¥¨
        ("300003", "ä¹æ™®åŒ»ç–—"), ("300014", "äº¿çº¬é”‚èƒ½"), ("300015", "çˆ±å°”çœ¼ç§‘"),
        ("300033", "åŒèŠ±é¡º"), ("300059", "ä¸œæ–¹è´¢å¯Œ"), ("300122", "æ™ºé£ç”Ÿç‰©"),
        ("300124", "æ±‡å·æŠ€æœ¯"), ("300142", "æ²ƒæ£®ç”Ÿç‰©"), ("300146", "æ±¤è‡£å€å¥"),
        ("300347", "æ³°æ ¼åŒ»è¯"), ("300408", "ä¸‰ç¯é›†å›¢"), ("300413", "èŠ’æœè¶…åª’"),
        ("300433", "è“æ€ç§‘æŠ€"), ("300450", "å…ˆå¯¼æ™ºèƒ½"), ("300454", "æ·±ä¿¡æœ"),
        ("300496", "ä¸­ç§‘åˆ›è¾¾"), ("300498", "æ¸©æ°è‚¡ä»½"), ("300529", "å¥å¸†ç”Ÿç‰©"),
        ("300558", "è´è¾¾è¯ä¸š"), ("300595", "æ¬§æ™®åº·è§†"), ("300601", "åº·æ³°ç”Ÿç‰©"),
        ("300628", "äº¿è”ç½‘ç»œ"), ("300661", "åœ£é‚¦è‚¡ä»½"), ("300750", "å®å¾·æ—¶ä»£"),
        ("300760", "è¿ˆç‘åŒ»ç–—"), ("300782", "å“èƒœå¾®"), ("300888", "ç¨³å¥åŒ»ç–—"),
        ("300896", "çˆ±ç¾å®¢"),

        # ç§‘åˆ›æ¿è‚¡ç¥¨
        ("688005", "å®¹ç™¾ç§‘æŠ€"), ("688009", "ä¸­å›½é€šå·"), ("688012", "ä¸­å¾®å…¬å¸"),
        ("688036", "ä¼ éŸ³æ§è‚¡"), ("688111", "é‡‘å±±åŠå…¬"), ("688126", "æ²ªç¡…äº§ä¸š"),
        ("688169", "çŸ³å¤´ç§‘æŠ€"), ("688180", "å›å®ç”Ÿç‰©"), ("688187", "æ—¶ä»£ç”µæ°”"),
        ("688188", "æŸæ¥šç”µå­"), ("688200", "åå³°æµ‹æ§"), ("688208", "é“é€šç§‘æŠ€"),
        ("688256", "å¯’æ­¦çºª"), ("688269", "å‡¯å› ç§‘æŠ€"), ("688271", "è”å½±åŒ»ç–—"),
        ("688303", "å¤§å…¨èƒ½æº"), ("688363", "åç†™ç”Ÿç‰©"), ("688396", "åæ¶¦å¾®"),
        ("688516", "å¥¥ç‰¹ç»´"), ("688520", "ç¥å·ç»†èƒ"), ("688536", "æ€ç‘æµ¦"),
        ("688561", "å¥‡å®‰ä¿¡"), ("688599", "å¤©åˆå…‰èƒ½"), ("688617", "æƒ æ³°åŒ»ç–—"),
        ("688658", "æ‚¦åº·è¯ä¸š"), ("688679", "é€šæºç¯å¢ƒ"), ("688696", "æç±³ç§‘æŠ€"),
        ("688728", "æ ¼ç§‘å¾®"), ("688772", "ç æµ·å† å®‡"), ("688798", "è‰¾ä¸ºç”µå­"),
        ("688799", "åçº³è¯å‚"), ("688819", "å¤©èƒ½è‚¡ä»½"),
    ]
    return stocks


def load_cached_tickers():
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å·²ä¿å­˜çš„Aè‚¡tickeråˆ—è¡¨"""
    ticker_file = TICKER_STORAGE_DIR / "cn_tickers.csv"
    if ticker_file.exists():
        try:
            df = pd.read_csv(ticker_file, dtype={'symbol': str})
            return [(str(row['symbol']).zfill(6), str(row['name'])) for _, row in df.iterrows()]
        except:
            return []
    return []


def save_tickers(tickers):
    """ä¿å­˜Aè‚¡tickeråˆ—è¡¨åˆ°æœ¬åœ°æ–‡ä»¶"""
    ticker_file = TICKER_STORAGE_DIR / "cn_tickers.csv"
    df = pd.DataFrame(tickers, columns=['symbol', 'name'])
    df.to_csv(ticker_file, index=False)
    logger.info(f"å·²ä¿å­˜ {len(tickers)} åªtickeråˆ° {ticker_file}")


def is_actual_cn_stock(symbol, name):
    """è¿‡æ»¤æ‰ETFã€åŸºé‡‘ã€å€ºåˆ¸ç­‰éè‚¡ç¥¨ç±»å‹"""
    if not symbol or not name:
        return False

    symbol = str(symbol).upper()
    name = str(name).upper()

    # è¿‡æ»¤ETFå’ŒåŸºé‡‘
    etf_keywords = ['ETF', 'åŸºé‡‘', 'æŒ‡æ•°', 'LOF', 'åˆ†çº§', 'è´§å¸', 'å€ºåˆ¸', 'FOF']
    for keyword in etf_keywords:
        if keyword in name:
            return False

    # è¿‡æ»¤STè‚¡ç¥¨ï¼ˆå¯é€‰ï¼Œå–æ¶ˆæ³¨é‡Šå¯è¿‡æ»¤STï¼‰
    # if 'ST' in name or '*ST' in name:
    #     return False

    # è¿‡æ»¤Bè‚¡ï¼ˆä»£ç ä»¥200ã€900å¼€å¤´ï¼‰
    if symbol.startswith('200') or symbol.startswith('900'):
        return False

    # è¿‡æ»¤å¯è½¬å€ºã€æƒè¯ç­‰
    if symbol.startswith('11') or symbol.startswith('12'):  # å¯è½¬å€ºä»£ç 
        return False

    return True


def filter_by_market(stocks, market):
    """æ ¹æ®å¸‚åœºç­›é€‰è‚¡ç¥¨"""
    if market == 'all':
        return stocks

    filtered = []
    for code, name in stocks:
        code = str(code).zfill(6)

        if market == 'sh':  # ä¸Šæµ·ä¸»æ¿ï¼ˆ60å¼€å¤´ï¼‰
            if code.startswith('60'):
                filtered.append((code, name))
        elif market == 'sz':  # æ·±åœ³ä¸»æ¿ï¼ˆ00å¼€å¤´ï¼‰
            if code.startswith('00'):
                filtered.append((code, name))
        elif market == 'cyb':  # åˆ›ä¸šæ¿ï¼ˆ30å¼€å¤´ï¼‰
            if code.startswith('30'):
                filtered.append((code, name))
        elif market == 'kcb':  # ç§‘åˆ›æ¿ï¼ˆ688å¼€å¤´ï¼‰
            if code.startswith('688'):
                filtered.append((code, name))
        elif market == 'bj':  # åŒ—äº¤æ‰€ï¼ˆ8å¼€å¤´æˆ–4å¼€å¤´ï¼‰
            if code.startswith('8') or code.startswith('4'):
                filtered.append((code, name))

    return filtered


def get_all_stock_codes():
    """è·å–Aè‚¡ä»£ç å’Œåç§°ï¼ˆé»˜è®¤è·å–å…¨éƒ¨Aè‚¡ï¼‰"""
    if USE_TICKER_CACHE:
        # ä½¿ç”¨ç¼“å­˜æ¨¡å¼
        cached_tickers = load_cached_tickers()
        if cached_tickers:
            logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„tickeråˆ—è¡¨ï¼Œå…± {len(cached_tickers)} åªè‚¡ç¥¨")
            tickers = cached_tickers
        else:
            logger.warning("âš ï¸  æœªæ‰¾åˆ°ç¼“å­˜çš„tickeråˆ—è¡¨ï¼Œæ­£åœ¨è·å–å…¨éƒ¨Aè‚¡...")
            tickers = fetch_all_cn_stocks()
            save_tickers(tickers)
    else:
        # é»˜è®¤æ¨¡å¼ï¼šæ¯æ¬¡éƒ½è·å–å…¨éƒ¨Aè‚¡
        logger.info("ğŸ“¡ æ­£åœ¨è·å–å…¨éƒ¨Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
        tickers = fetch_all_cn_stocks()
        save_tickers(tickers)

    # è¿‡æ»¤ETF/åŸºé‡‘ç­‰éè‚¡ç¥¨
    logger.info("æ­£åœ¨è¿‡æ»¤ETFå’Œéè‚¡ç¥¨ç±»å‹...")
    original_count = len(tickers)
    filtered_tickers = [(symbol, name) for symbol, name in tickers if is_actual_cn_stock(symbol, name)]
    filtered_count = original_count - len(filtered_tickers)
    logger.info(f"ğŸ“Š è¿‡æ»¤æ‰ {filtered_count} åªETF/åŸºé‡‘/å€ºåˆ¸ç­‰ï¼Œå‰©ä½™ {len(filtered_tickers)} åªçº¯è‚¡ç¥¨")

    # æ ¹æ®å¸‚åœºç­›é€‰
    if MARKET_FILTER != 'all':
        market_names = {
            'sh': 'ä¸Šæµ·ä¸»æ¿',
            'sz': 'æ·±åœ³ä¸»æ¿',
            'cyb': 'åˆ›ä¸šæ¿',
            'kcb': 'ç§‘åˆ›æ¿',
            'bj': 'åŒ—äº¤æ‰€'
        }
        filtered_tickers = filter_by_market(filtered_tickers, MARKET_FILTER)
        logger.info(f"ğŸ“Š ç­›é€‰ {market_names.get(MARKET_FILTER, MARKET_FILTER)} è‚¡ç¥¨ï¼Œå…± {len(filtered_tickers)} åª")

    return filtered_tickers


def load_delisted_stocks():
    """åŠ è½½å·²é€€å¸‚è‚¡ç¥¨åˆ—è¡¨"""
    delisted = set()
    if DELISTED_STOCKS_FILE.exists():
        try:
            with open(DELISTED_STOCKS_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    symbol = line.strip()
                    if symbol and not symbol.startswith('#'):
                        delisted.add(symbol)
            logger.info(f"ğŸ“‹ åŠ è½½äº† {len(delisted)} åªå·²é€€å¸‚è‚¡ç¥¨è¿‡æ»¤åˆ—è¡¨")
        except Exception as e:
            logger.error(f"âš ï¸  è¯»å–å·²é€€å¸‚è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
    return delisted


def save_delisted_stock(symbol):
    """å°†è‚¡ç¥¨ä»£ç æ·»åŠ åˆ°å·²é€€å¸‚è‚¡ç¥¨åˆ—è¡¨"""
    try:
        existing = load_delisted_stocks()
        if symbol not in existing:
            with open(DELISTED_STOCKS_FILE, 'a', encoding='utf-8') as f:
                f.write(f"{symbol}\n")
            logger.info(f"ğŸ“ å·²å°† {symbol} æ·»åŠ åˆ°å·²é€€å¸‚è‚¡ç¥¨åˆ—è¡¨")
    except Exception as e:
        logger.error(f"âš ï¸  ä¿å­˜å·²é€€å¸‚è‚¡ç¥¨å¤±è´¥: {e}")


def get_cache_filename(symbol):
    """è·å–è‚¡ç¥¨æ•°æ®ç¼“å­˜æ–‡ä»¶å"""
    return CACHE_DIR / f"{symbol}_data.json"


def load_cached_stock_data(symbol):
    """ä»ç¼“å­˜åŠ è½½è‚¡ç¥¨æ•°æ®"""
    cache_file = get_cache_filename(symbol)
    if cache_file.exists():
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                cache_time = datetime.datetime.fromisoformat(data['cache_time'])
                if datetime.datetime.now() - cache_time < datetime.timedelta(days=1):
                    return data['stock_data']
        except Exception as e:
            logger.warning(f"âš ï¸  è¯»å–ç¼“å­˜å¤±è´¥ {symbol}: {e}")
    return None


def save_stock_data_to_cache(symbol, stock_data):
    """ä¿å­˜è‚¡ç¥¨æ•°æ®åˆ°ç¼“å­˜"""
    if stock_data is None:
        return

    cache_file = get_cache_filename(symbol)
    try:
        cache_data = {
            'cache_time': datetime.datetime.now().isoformat(),
            'stock_data': stock_data
        }
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥ {symbol}: {e}")


def clear_all_cache():
    """æ¸…é™¤æ‰€æœ‰ç¼“å­˜çš„è‚¡ç¥¨æ•°æ®"""
    if CACHE_DIR.exists():
        import shutil
        try:
            shutil.rmtree(CACHE_DIR)
            CACHE_DIR.mkdir(exist_ok=True)
            logger.info("ğŸ—‘ï¸  å·²æ¸…é™¤æ‰€æœ‰Aè‚¡æ•°æ®ç¼“å­˜")
        except Exception as e:
            logger.error(f"âš ï¸  æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
    else:
        logger.info("ğŸ“­ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…é™¤")


def fetch_stock_history_cn(symbol, days=90):
    """ä½¿ç”¨akshareè·å–Aè‚¡å†å²è¡Œæƒ…"""
    try:
        import akshare as ak

        # ç¡®ä¿ä»£ç æ ¼å¼æ­£ç¡®ï¼ˆ6ä½æ•°å­—ï¼‰
        symbol = str(symbol).zfill(6)

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.datetime.now()
        start_date = end_date - datetime.timedelta(days=days)

        # ä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ•°æ®æºè·å–æ—¥Kæ•°æ®
        df = ak.stock_zh_a_hist(
            symbol=symbol,
            period="daily",
            start_date=start_date.strftime('%Y%m%d'),
            end_date=end_date.strftime('%Y%m%d'),
            adjust="qfq"  # å‰å¤æƒ
        )

        if df is None or df.empty:
            return None

        # æ ‡å‡†åŒ–åˆ—å
        df = df.rename(columns={
            'æ—¥æœŸ': 'æ—¥æœŸ',
            'æ”¶ç›˜': 'æ”¶ç›˜',
            'æœ€é«˜': 'æœ€é«˜',
            'æœ€ä½': 'æœ€ä½',
            'å¼€ç›˜': 'å¼€ç›˜',
            'æˆäº¤é‡': 'æˆäº¤é‡',
            'æ¢æ‰‹ç‡': 'æ¢æ‰‹ç‡'
        })

        return df

    except Exception as e:
        error_str = str(e).lower()
        if 'delisted' in error_str or 'é€€å¸‚' in error_str:
            save_delisted_stock(symbol)
        return None


def get_stock_info_cn(symbol):
    """è·å–Aè‚¡è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    try:
        import akshare as ak

        symbol = str(symbol).zfill(6)

        info = {
            'market_cap': None,
            'industry': 'N/A',
            'list_date': 'N/A',
            'fifty_two_week_high': 0,
            'fifty_two_week_low': 0
        }

        try:
            # è·å–ä¸ªè‚¡ä¿¡æ¯
            stock_info = ak.stock_individual_info_em(symbol=symbol)
            if stock_info is not None and not stock_info.empty:
                info_dict = dict(zip(stock_info['item'], stock_info['value']))

                # æ€»å¸‚å€¼ - ä¸œæ–¹è´¢å¯Œè¿”å›çš„å·²ç»æ˜¯å…ƒä¸ºå•ä½
                if 'æ€»å¸‚å€¼' in info_dict:
                    try:
                        market_cap_val = info_dict['æ€»å¸‚å€¼']
                        if isinstance(market_cap_val, (int, float)):
                            info['market_cap'] = float(market_cap_val)  # å·²ç»æ˜¯å…ƒä¸ºå•ä½
                        else:
                            market_cap_str = str(market_cap_val)
                            market_cap_str = market_cap_str.replace(',', '').replace('äº¿', '')
                            info['market_cap'] = float(market_cap_str)
                    except:
                        pass

                # è¡Œä¸š
                if 'è¡Œä¸š' in info_dict:
                    info['industry'] = str(info_dict['è¡Œä¸š'])

                # ä¸Šå¸‚æ—¥æœŸ
                if 'ä¸Šå¸‚æ—¶é—´' in info_dict:
                    info['list_date'] = str(info_dict['ä¸Šå¸‚æ—¶é—´'])
        except:
            pass

        # è·å–52å‘¨æœ€é«˜æœ€ä½ä»·
        try:
            # è·å–ä¸€å¹´çš„å†å²æ•°æ®æ¥è®¡ç®—52å‘¨é«˜ä½ä»·
            end_date = datetime.datetime.now()
            start_date = end_date - datetime.timedelta(days=365)

            df_year = ak.stock_zh_a_hist(
                symbol=symbol,
                period="daily",
                start_date=start_date.strftime('%Y%m%d'),
                end_date=end_date.strftime('%Y%m%d'),
                adjust="qfq"
            )

            if df_year is not None and not df_year.empty:
                info['fifty_two_week_high'] = float(df_year['æœ€é«˜'].max())
                info['fifty_two_week_low'] = float(df_year['æœ€ä½'].min())
        except:
            pass

        return info

    except Exception as e:
        return {
            'market_cap': None,
            'industry': 'N/A',
            'list_date': 'N/A',
            'fifty_two_week_high': 0,
            'fifty_two_week_low': 0
        }


def is_strong_stock(symbol, name, delisted_stocks=None):
    """ä½¿ç”¨ç»¼åˆæŠ€æœ¯æŒ‡æ ‡åˆ¤æ–­è‚¡ç¥¨å¼ºåŠ¿ç¨‹åº¦"""
    # æ£€æŸ¥æ˜¯å¦åœ¨å·²é€€å¸‚åˆ—è¡¨ä¸­
    if delisted_stocks and symbol in delisted_stocks:
        return None

    try:
        # ä½¿ç”¨æ•°æ®ç¼“å­˜
        if USE_DATA_CACHE:
            cached_result = load_cached_stock_data(symbol)
            if cached_result:
                cache_date = cached_result.get('æ—¥æœŸ', '')
                today = datetime.datetime.now().strftime('%Y-%m-%d')
                if cache_date == today:
                    logger.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜æ•°æ®: {symbol}")
                    return cached_result

        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        stock_info = get_stock_info_cn(symbol)
        market_cap = stock_info.get('market_cap')
        industry = stock_info.get('industry', 'N/A')
        list_date = stock_info.get('list_date', 'N/A')
        fifty_two_week_high = stock_info.get('fifty_two_week_high', 0)
        fifty_two_week_low = stock_info.get('fifty_two_week_low', 0)

        # å¸‚å€¼è¿‡æ»¤ï¼šè¿‡æ»¤è¶…å¤§ç›˜è‚¡ï¼ˆ>1ä¸‡äº¿äººæ°‘å¸ï¼‰
        if market_cap:
            if market_cap > 1_000_000_000_000:  # 1ä¸‡äº¿äººæ°‘å¸
                market_cap_billions = market_cap / 100_000_000
                logger.info(f"ğŸš« è¿‡æ»¤è¶…å¤§ç›˜è‚¡: {symbol} (å¸‚å€¼: {market_cap_billions:.0f}äº¿)")
                return None

        # è®¡ç®—52å‘¨æ³¢åŠ¨å¹…åº¦
        week_52_range_pct = 0
        if fifty_two_week_low > 0 and fifty_two_week_high > 0:
            week_52_range_pct = ((fifty_two_week_high - fifty_two_week_low) / fifty_two_week_low) * 100
            # è¿‡æ»¤æ¡ä»¶ï¼š52å‘¨æ³¢åŠ¨å¹…åº¦å¿…é¡» >= 250%
            if week_52_range_pct < 250:
                logger.info(f"ğŸš« è¿‡æ»¤æ³¢åŠ¨å¹…åº¦ä¸è¶³çš„è‚¡ç¥¨: {symbol} (52å‘¨æ³¢åŠ¨: {week_52_range_pct:.1f}% < 250%)")
                return None

        # è·å–å†å²æ•°æ®
        df = fetch_stock_history_cn(symbol, days=90)

        if df is None or df.empty or len(df) < 25:
            return None

        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        df['MA5'] = df['æ”¶ç›˜'].rolling(5).mean()
        df['MA10'] = df['æ”¶ç›˜'].rolling(10).mean()
        df['MA20'] = df['æ”¶ç›˜'].rolling(20).mean()

        # MACDæŒ‡æ ‡
        df['MACD_diff'] = df['æ”¶ç›˜'].ewm(span=12).mean() - df['æ”¶ç›˜'].ewm(span=26).mean()
        df['MACD_dea'] = df['MACD_diff'].ewm(span=9).mean()

        # æˆäº¤é‡å‡çº¿
        df['VolMA5'] = df['æˆäº¤é‡'].rolling(5).mean()

        # 20å¤©æ¶¨å¹…
        df['RS_20d'] = df['æ”¶ç›˜'].pct_change(periods=20)

        # è·å–æœ€æ–°æ•°æ®
        latest = df.iloc[-1]

        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_fields = ['MA5', 'MA10', 'MA20', 'æ”¶ç›˜', 'MACD_diff', 'MACD_dea', 'æˆäº¤é‡', 'VolMA5']
        for field in required_fields:
            if field not in latest or pd.isna(latest[field]):
                return None

        # è·å–æ•°å€¼
        ma5_val = float(latest['MA5'])
        ma10_val = float(latest['MA10'])
        ma20_val = float(latest['MA20'])
        close_val = float(latest['æ”¶ç›˜'])
        macd_val = float(latest['MACD_diff'])
        dea_val = float(latest['MACD_dea'])
        vol_val = float(latest['æˆäº¤é‡'])
        vol_ma5_val = float(latest['VolMA5'])

        # è¶‹åŠ¿å¼ºåº¦åˆ¤æ–­
        conditions = {
            'çŸ­æœŸè¶‹åŠ¿': ma5_val > ma10_val,
            'ä¸­æœŸè¶‹åŠ¿': ma10_val > ma20_val,
            'ä»·æ ¼å¼ºåŠ¿': close_val > ma5_val,
            'MACDä¿¡å·': macd_val > dea_val and macd_val > 0,
            'æˆäº¤é‡': vol_val > vol_ma5_val * 0.5,
        }

        # 20å¤©æ¶¨å¹…æ¡ä»¶
        rs_20d_float = 0
        if 'RS_20d' in latest.index and not pd.isna(latest['RS_20d']):
            rs_20d_float = float(latest['RS_20d'])
            conditions['ç›¸å¯¹å¼ºåº¦'] = rs_20d_float > 0.15

        # è®¡ç®—æ»¡è¶³æ¡ä»¶çš„æ•°é‡
        met_conditions = sum(conditions.values())
        total_conditions = len(conditions)

        # åªæœ‰æ»¡è¶³æ‰€æœ‰6ä¸ªæ¡ä»¶æ‰å†™å…¥
        if met_conditions == total_conditions and total_conditions == 6:
            date_str = str(latest['æ—¥æœŸ'])[:10] if 'æ—¥æœŸ' in latest.index else datetime.datetime.now().strftime(
                '%Y-%m-%d')

            # æ ¼å¼åŒ–å¸‚å€¼æ˜¾ç¤º
            market_cap_display = "N/A"
            if market_cap:
                if market_cap >= 100_000_000_000:  # 1000äº¿ä»¥ä¸Š
                    market_cap_display = f"Â¥{market_cap / 100_000_000:.0f}äº¿"
                elif market_cap >= 100_000_000:  # 1äº¿ä»¥ä¸Š
                    market_cap_display = f"Â¥{market_cap / 100_000_000:.2f}äº¿"
                else:
                    market_cap_display = f"Â¥{market_cap:,.0f}"

            # è®¡ç®—è·52å‘¨é«˜ä½ä»·çš„ç™¾åˆ†æ¯”
            pct_from_high = 0
            pct_from_low = 0
            if fifty_two_week_high > 0:
                pct_from_high = ((close_val - fifty_two_week_high) / fifty_two_week_high) * 100
            if fifty_two_week_low > 0:
                pct_from_low = ((close_val - fifty_two_week_low) / fifty_two_week_low) * 100

            result = {
                "ä»£ç ": symbol,
                "åç§°": name,
                "52å‘¨æ³¢åŠ¨å¹…åº¦": f"{round(week_52_range_pct, 2)}%" if week_52_range_pct > 0 else "N/A",
                "52å‘¨æœ€é«˜": round(fifty_two_week_high, 2) if fifty_two_week_high > 0 else "N/A",
                "è·52å‘¨é«˜ç‚¹": f"{round(pct_from_high, 2)}%" if fifty_two_week_high > 0 else "N/A",
                "52å‘¨æœ€ä½": round(fifty_two_week_low, 2) if fifty_two_week_low > 0 else "N/A",
                "è·52å‘¨ä½ç‚¹": f"{round(pct_from_low, 2)}%" if fifty_two_week_low > 0 else "N/A",
                "ä¸Šå¸‚æ—¥æœŸ": list_date,
                "æ”¶ç›˜ä»·": round(close_val, 2),
                "å¸‚å€¼": market_cap_display,
                "è¡Œä¸š": industry,
                "MA5": round(ma5_val, 2),
                "MA10": round(ma10_val, 2),
                "MA20": round(ma20_val, 2),
                "MACD": round(macd_val, 4),
                "MACD_DEA": round(dea_val, 4),
                "æˆäº¤é‡å€æ•°": round(vol_val / vol_ma5_val, 2) if vol_ma5_val > 0 else 0,
                "20å¤©æ¶¨å¹…": round(rs_20d_float * 100, 2),
                "æ»¡è¶³æ¡ä»¶": f"{met_conditions}/{total_conditions}",
                "æ¡ä»¶è¯¦æƒ…": '|'.join([k for k, v in conditions.items() if v])
            }

            if USE_DATA_CACHE:
                save_stock_data_to_cache(symbol, result)
            return result
        else:
            if USE_DATA_CACHE:
                negative_result = {
                    "ä»£ç ": symbol,
                    "åç§°": name,
                    "æ—¥æœŸ": datetime.datetime.now().strftime('%Y-%m-%d'),
                    "ä¸ç¬¦åˆæ¡ä»¶": True,
                    "æ»¡è¶³æ¡ä»¶": f"{met_conditions}/{total_conditions}"
                }
                save_stock_data_to_cache(symbol, negative_result)
            return None

    except Exception as e:
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in ['delisted', 'é€€å¸‚', 'no data', 'not found']):
            if delisted_stocks is not None:
                save_delisted_stock(symbol)
        return None


def get_output_filename():
    """ç”Ÿæˆå¸¦æ—¥æœŸåç¼€çš„æ–‡ä»¶å"""
    now = datetime.datetime.now()
    return str(OUTPUT_DIR / f"strong_stocks_cn_{now.strftime('%Y%m%d_%H')}.xlsx")


def save_strong_stocks_to_db(df: pd.DataFrame):
    """å°†å¼ºåŠ¿è‚¡ç¥¨æ‰«æç»“æœä¿å­˜åˆ°æ•°æ®åº“"""
    if df.empty:
        logger.info("æ²¡æœ‰æ‰«æåˆ°å¼ºåŠ¿è‚¡ç¥¨ï¼Œæ— éœ€ä¿å­˜åˆ°æ•°æ®åº“ã€‚")
        return

    db = get_db()
    # ç¡®ä¿ strong_stocks è¡¨å·²åˆ›å»º
    Base.metadata.create_all(db._engine)
    
    with db.get_session() as session:
        try:
            for _, row in df.iterrows():
                stock = StrongStock(
                    scan_time=datetime.datetime.now(), # è®°å½•å½“å‰æ‰«ææ—¶é—´
                    stock_code=row['ä»£ç '],
                    stock_name=row['åç§°'],
                    close_price=row['æ”¶ç›˜ä»·'],
                    market_cap=row['å¸‚å€¼'],
                    industry=row['è¡Œä¸š'],
                    list_date=row['ä¸Šå¸‚æ—¥æœŸ'],
                    ma5=row['MA5'],
                    ma10=row['MA10'],
                    ma20=row['MA20'],
                    macd=row['MACD'],
                    macd_dea=row['MACD_DEA'],
                    vol_ratio=row['æˆäº¤é‡å€æ•°'],
                    increase_20d=row['20å¤©æ¶¨å¹…'],
                    week_52_range=row['52å‘¨æ³¢åŠ¨å¹…åº¦'],
                    week_52_high=row['52å‘¨æœ€é«˜'] if row['52å‘¨æœ€é«˜'] != 'N/A' else None,
                    pct_from_high=row['è·52å‘¨é«˜ç‚¹'],
                    week_52_low=row['52å‘¨æœ€ä½'] if row['52å‘¨æœ€ä½'] != 'N/A' else None,
                    pct_from_low=row['è·52å‘¨ä½ç‚¹'],
                    met_conditions=row['æ»¡è¶³æ¡ä»¶'],
                    condition_details=row['æ¡ä»¶è¯¦æƒ…']
                )
                session.merge(stock) # ä½¿ç”¨ merge è¿›è¡Œ UPSERT æ“ä½œ
            session.commit()
            logger.info(f"æˆåŠŸå°† {len(df)} æ¡å¼ºåŠ¿è‚¡ç¥¨æ‰«æç»“æœä¿å­˜åˆ°æ•°æ®åº“ã€‚")
        except Exception as e:
            session.rollback()
            logger.error(f"ä¿å­˜å¼ºåŠ¿è‚¡ç¥¨æ‰«æç»“æœåˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}", exc_info=True)


def scan_market():
    """æ‰«æAè‚¡å¸‚åœº"""
    start_time = datetime.datetime.now()
    logger.info(f"\n{'=' * 60}")
    logger.info(f"å¼€å§‹æ‰«æAè‚¡å¼ºåŠ¿è‚¡ç¥¨...")
    logger.info(f"æ‰«ææ¡ä»¶: MA5>MA10 + MA10>MA20 + ä»·æ ¼>MA5 + MACDé‡‘å‰ä¸ºæ­£ + æˆäº¤é‡ä¸è¿‡åº¦èç¼© + 20å¤©æ¶¨å¹…>15%")
    logger.info(f"æ’åºè§„åˆ™: æŒ‰20å¤©æ¶¨å¹…ä»å°åˆ°å¤§æ’åº")
    logger.info(f"è¿‡æ»¤æ¡ä»¶: æ’é™¤ETF/åŸºé‡‘/å€ºåˆ¸ + å¸‚å€¼<1ä¸‡äº¿ + 52å‘¨æ³¢åŠ¨å¹…åº¦>=250%")
    logger.info(f"å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"{'=' * 60}\n")

    if CLEAR_CACHE:
        clear_all_cache()

    delisted_stocks = load_delisted_stocks()
    codes = get_all_stock_codes()

    # è¿‡æ»¤å·²é€€å¸‚è‚¡ç¥¨
    if delisted_stocks:
        original_count = len(codes)
        codes = [(code, name) for code, name in codes if code not in delisted_stocks]
        filtered_count = original_count - len(codes)
        if filtered_count > 0:
            logger.info(f"ğŸš« å·²è¿‡æ»¤ {filtered_count} åªå·²é€€å¸‚è‚¡ç¥¨\n")

    # æµ‹è¯•æ¨¡å¼
    if TEST_LIMIT > 0:
        codes = codes[:TEST_LIMIT]
        logger.warning(f"âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šåªæ‰«æå‰ {TEST_LIMIT} åªè‚¡ç¥¨\n")

    logger.info(f"ğŸ“Š æ€»å…±éœ€è¦æ‰«æ {len(codes)} åªè‚¡ç¥¨")
    cache_strategy = "ä½¿ç”¨è‚¡ç¥¨æ•°æ®ç¼“å­˜" if USE_DATA_CACHE else "å®æ—¶è·å–æ•°æ®"
    logger.info(f"ğŸ’¾ ç¼“å­˜ç­–ç•¥ï¼š{cache_strategy}\n")

    results = []
    skipped = []
    output_file = get_output_filename()

    for idx, (code, name) in enumerate(codes, 1):
        code_str = str(code).zfill(6)
        name_str = str(name)
        logger.info(f"[{idx:4d}/{len(codes)}] ğŸ” æ‰«æ: {code_str} - {name_str[:20]}")

        try:
            res = is_strong_stock(code_str, name_str, delisted_stocks)
            if res:
                results.append(res)

                # æŒ‰20å¤©æ¶¨å¹…æ’åº
                def sort_key(x):
                    return x.get('20å¤©æ¶¨å¹…', 0)

                results.sort(key=sort_key)
                log_strong_stock(res)
                logger.info(f"âœ… æ‰¾åˆ°å¼ºåŠ¿è‚¡ç¥¨ï¼å½“å‰å…± {len(results)} åªï¼š")
                logger.info(f"   {code_str}: æ”¶ç›˜ä»·=Â¥{res['æ”¶ç›˜ä»·']}, æ»¡è¶³{res['æ»¡è¶³æ¡ä»¶']}æ¡ä»¶, 20å¤©æ¶¨å¹…{res['20å¤©æ¶¨å¹…']}%")
        except Exception as e:
            logger.error(f"âŒ æ‰«æ {code_str} æ—¶å‡ºé”™: {e}", exc_info=True)
            skipped.append((code_str, name_str))

        time.sleep(random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX))

        if idx % BATCH_SIZE == 0:
            elapsed = (datetime.datetime.now() - start_time).total_seconds()
            logger.info(f"\nâ¸ï¸  å·²æ‰«æ {idx} åªï¼Œä¼‘æ¯ {BATCH_PAUSE} ç§’...")
            logger.info(f"   å·²ç”¨æ—¶: {elapsed:.1f} ç§’ï¼Œè¿›åº¦: {idx / len(codes) * 100:.1f}%")
            if results:
                logger.info(f"   ğŸ“ˆ å½“å‰å¼ºåŠ¿è‚¡ç¥¨å‰3å:")
                for i, top_stock in enumerate(results[:3], 1):
                    logger.info(f"     {i}. {top_stock['ä»£ç ']} {top_stock['åç§°'][:10]}")
            time.sleep(BATCH_PAUSE)
            logger.info("")

    end_time = datetime.datetime.now()
    elapsed_time = (end_time - start_time).total_seconds()

    # æœ€ç»ˆæ’åº
    def sort_key(x):
        return x.get('20å¤©æ¶¨å¹…', 0)

    results.sort(key=sort_key)
    df = pd.DataFrame(results)

    logger.info(f"\n{'=' * 60}")
    logger.info(f"æ‰«æå®Œæˆï¼")
    logger.info(f"ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"æ€»ç”¨æ—¶: {elapsed_time:.1f} ç§’ ({elapsed_time / 60:.1f} åˆ†é’Ÿ)")
    logger.info(f"æ‰«æè‚¡ç¥¨æ•°: {len(codes)}")
    logger.info(f"ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨: {len(results)} åª")
    logger.info(f"è·³è¿‡çš„è‚¡ç¥¨: {len(skipped)} åª")
    logger.info(f"{'=' * 60}\n")

    if not df.empty:
        try:
            df.to_excel(output_file, index=False)
            logger.info(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            save_strong_stocks_to_db(df) # è°ƒç”¨ä¿å­˜åˆ°æ•°æ®åº“çš„å‡½æ•°
        except PermissionError:
            logger.error(f"âŒ æ— æ³•å†™å…¥ {output_file}ï¼Œè¯·å…³é—­ Excel æ–‡ä»¶åé‡è¯•ã€‚")

    return df

if __name__ == "__main__":
    # æ£€æŸ¥akshareæ˜¯å¦å®‰è£…
    try:
        import akshare as ak

        logger.info(f"âœ… akshare ç‰ˆæœ¬: {ak.__version__}")
    except ImportError:
        logger.error("âŒ è¯·å…ˆå®‰è£…akshareåº“:")
        logger.error("   pip install akshare")
        logger.error("   æˆ–è€…: ./venv/bin/pip install akshare")
        exit(1)

    result_df = scan_market()
    if not result_df.empty:
        logger.info("\nğŸ“‹ æ‰«æç»“æœè¯¦æƒ…ï¼ˆæŒ‰20å¤©æ¶¨å¹…ä»å°åˆ°å¤§æ’åºï¼‰ï¼š")
        logger.info("=" * 80)
        logger.info(f"\n{result_df.to_string(index=False)}")
        logger.info("=" * 80)
        # output_file å˜é‡åœ¨ scan_market å†…éƒ¨å®šä¹‰ï¼Œè¿™é‡Œæ— æ³•ç›´æ¥è®¿é—®ï¼Œæ‰€ä»¥æ³¨é‡Šæ‰
        # logger.info(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        logger.info(f"ğŸ“ å…± {len(result_df)} åªç¬¦åˆæ¡ä»¶çš„Aè‚¡\n")
    else:
        logger.warning("\nâš ï¸  ä»Šå¤©æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³å…¨éƒ¨6ä¸ªæ¡ä»¶çš„Aè‚¡å¼ºåŠ¿è‚¡ç¥¨ã€‚\n")
